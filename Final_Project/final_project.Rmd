---
title: "Final"
output: 
  pdf_document: 
    keep_tex: yes
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Questions
1)	Consider the following blood pressure dataset (IC_BP_v2.csv). Perform the following operations
a.	Convert BP alerts to BP status


``` {r q1a}
library(tidyverse)
df <- read.csv("IC_BP_v2.csv", header=TRUE,sep=",")

#View(df)

str(df)

df <- df %>%
  rename(BPStatus = BPAlerts)

sample_n(df,10)
```

b.	Define Hypotension-1 & Normal as Controlled blood pressure Hypotension-2, Hypertension-1, Hypertension-2 & Hypertension-3 as Uncontrolled blood pressure: Controlled & Uncontrolled blood pressure as 1 or 0 (Dichotomous Outcomes) 

``` {r q1b}
#create number of groups before I change them so I can verify the numbers are correct afterwards
orig_bp_status <-df %>%
  group_by(BPStatus) %>%
  summarise(n())

#Change the names
df <- mutate(df,"BPStatus" = ifelse(BPStatus == "Hypo1",1,
                               ifelse(BPStatus == "Normal",1,
                                      ifelse(BPStatus == "HTN1",0,
                                             ifelse(BPStatus == "HTN2",0,
                                                    ifelse(BPStatus == "HTN3",0,
                                                          ifelse(BPStatus=="Hypo2",0,"NULL")))))) )


#get numbers of the new groups
new_bp_status <- df %>%
  group_by(BPStatus) %>%
  summarise(n())


#Verify that # of entries in Hypo1 + Normal = # of entries that are labeled 1
filter(orig_bp_status, BPStatus == "Hypo1")$`n()` +
  filter(orig_bp_status, BPStatus == "Normal")$`n()` == filter(new_bp_status, BPStatus == 1)$`n()`

#Verify that # of entries in Hypo2 + HTN1 + HTN2 + HTN3 = # of entries that are labeled 0
filter(orig_bp_status, BPStatus == "Hypo2")$`n()` +
  filter(orig_bp_status, BPStatus == "HTN1")$`n()` +
    filter(orig_bp_status, BPStatus == "HTN2")$`n()` +
             filter(orig_bp_status, BPStatus == "HTN3")$`n()` == filter(new_bp_status, BPStatus == 0)$`n()`

#Verify that Null = Null
filter(orig_bp_status, BPStatus == "NULL")$`n()` ==
  filter(new_bp_status, BPStatus == "NULL")$`n()`


sample_n(df, 10)
```
c.	Merge this table with demographics (SQL table) to obtain their enrollment dates

``` {r q1c}
library("RODBC")

myconn<-odbcConnect("qbs181","aivanov","aivanov@qbs181")
demo <-sqlQuery(myconn,"select * from demographics")

#View(demo)

nrow(demo)
nrow(df)

length(unique(demo$contactid))
length(unique(df$ID))




merged_table <- left_join(df, demo,by = (c("ID"="contactid")))

length(unique(merged_table$ID))

sample_n(merged_table, 10)



```

d.	Create a 12-week interval of averaged scores of each customer

``` {r q1d}

(max(df$ObservedTime) - min(df$ObservedTime))


df_hours <- df %>%
  group_by(ID) %>%
  summarize(n(), max(ObservedTime), min(ObservedTime), 
            diff = ((max(ObservedTime) - min(ObservedTime))/24))


df_hours[df_hours$diff > 13,]


df2 <- df %>%
  group_by(ID) %>%
  summarize(n(), max(ObservedTime), min(ObservedTime), 
            diff = ((max(ObservedTime) - min(ObservedTime))/7))


sum(df2$diff>12)

df <- df %>%
    group_by(ID) %>%
    arrange(ObservedTime, .by_group = TRUE) %>%
    mutate(StandardizedTime = ObservedTime - min(ObservedTime) + 1)



df$week <- ceiling(df$StandardizedTime/7)






sum((df$BPStatus=="NULL"))
df <-df[!(df$BPStatus=="NULL"),]
sum((df$BPStatus=="NULL"))


df$BPStatus <- as.numeric(df$BPStatus)

ID_score_byweek <- df %>%
  group_by(ID, week) %>%
  summarize("number_of_IDs" = n(), mean(BPStatus))

sum((merged_table$tri_enrollmentcompletedate=="NULL"))
mt <- merged_table[!(merged_table$tri_enrollmentcompletedate=="NULL"),]
sum(mt$tri_enrollmentcompletedate=="NULL")


mt$new_observed_time <- as.Date(mt$ObservedTime, origin= "1900-01-01")


sum((mt$new_observed_time - mt$enrollmentDate)<0)

library(lubridate)

mt$BPStatus <- as.numeric(mt$BPStatus)

mt2 <- mt %>% 
  group_by(ID, week = floor_date(new_observed_time, unit = "week")) %>% 
  summarize("BPStatus_number" = n(), mean(BPStatus))



id_score_week <- data.frame(ID_score_byweek)


sample_n(id_score_week, 10)
```

e.	Compare the scores from baseline (first week) to follow-up scores (12 weeks)

``` {r q1e}

id_score_1_12 <- filter(id_score_week, week==1 | week==12)

head(id_score_1_12)

keeps <- c("ID","week","mean.BPStatus.")
df3 = id_score_1_12[keeps]

head(df3)

df4 <- spread(df3,week,mean.BPStatus.)

head(df4)
df_complete <- df4[complete.cases(df4), ]

length(unique(df_complete$ID))


df_complete

df_complete[df_complete$`1` == 1,]

df_complete[df_complete$`1` == 0,]

df_complete[df_complete$`12` == 1,]

df_complete[df_complete$`12` == 0,]

```

 
f.	How many customers were brought from uncontrolled regime to controlled regime after 12 weeks of intervention?

``` {r q1f}

df_complete$diff = df_complete$`12` - df_complete$`1`

(df_complete[df_complete$diff>0,])


(filter(df_complete, `1` == 0, `12` == 1))


(filter(df_complete, `1` < 1, `12` == 1))

```




# Question 2



Select A.*, B.*, C.*  into aivanov.final

from Demographics A

Inner Join

Conditions B

on

A.contactid = B.tri_patientid

inner join

TextMessages C

on

A.contactid = C.tri_contactid


SELECT

  aivanov.final.* into aivanov.final2
  
FROM

  (SELECT
  
     contactid, MAX(TextSentDate) AS maxdate
     
   FROM
   
     aivanov.final
     
   GROUP BY
   
     contactid) AS latest_orders
     
INNER JOIN

  aivanov.final
  
ON

  aivanov.final.contactid = latest_orders.contactid AND
  
  aivanov.final.TextSentDate = latest_orders.maxdate



WITH cte AS 

( SELECT *, ROW_NUMBER() OVER (PARTITION BY contactid ORDER BY TextSentDate DESC)  AS rn

FROM aivanov.final2

)

SELECT * into aivanov.final3

FROM cte

WHERE rn = 1

select TOP 10 * from aivanov.final3



# Questions 3

3)	Repeat Question 2 in R. 
Hint: You might want to use tidyr/dplyr packages


``` {r q3}
#import the datasets from sql
dems <- sqlQuery(myconn,"select * from demographics")
cond <- sqlQuery(myconn,"select * from conditions")
text <- sqlQuery(myconn,"select * from textmessages")

#identify the number of rows
nrow(dems)
nrow(cond)
nrow(text)


dems_cond_text <- dems %>% 
  full_join(cond,  by = c("contactid"="tri_patientid")) %>%
  full_join(text, by=c("contactid"="tri_contactId"))

dems_cond_text2 <- dems %>% 
  inner_join(cond,  by = c("contactid"="tri_patientid")) %>%
  inner_join(text, by=c("contactid"="tri_contactId"))

nrow(dems_cond_text)

length(unique(dems_cond_text$contactid))

#group by contactid and only take max sent date
final_dataset2 <- dems_cond_text2 %>%
  group_by(contactid) %>%
  slice(which.max(as.Date(TextSentDate, '%m/%d/%Y')))

nrow(final_dataset2)


#check if contactid is duplicated
sum(duplicated(final_dataset2$contactid))
final_dataset2 <- data.frame(final_dataset2)
sample_n(final_dataset2, 10)
```

# Question 4

GitHub link is https://github.com/d32402f/Data_Wrangling_Project_and_Tasks

